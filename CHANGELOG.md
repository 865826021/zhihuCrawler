## 2015-10-07 晚上

---

整套流程已经可以跑了，没有任何问题。问题只是性能不好。

我惊奇的发现通过linux命令行似乎不会崩溃。挺好的。

正在写`curl_muti`这一块儿的内容，说实话，文档很难看懂。

明天再弄吧。

`swoole`也准备开始了！

## 2015-10-07 下午

---

Subject: 添加宕机恢复

每次输入数据库之后就会把当前的次数和id写入cache文件。

一旦崩溃重启应用，会从cache文件中拿出数据，接着运行。

嘿嘿，这使得写循环脚本成为了可能哦~

不过，切换两个任务要把cache给删掉。不然会出错的。

嗯，可以写个命令行脚本啦


## 2015-10-07

------

Subject: 正常运行

今天已经可以正常运行了。一个是用户表的获取，另一个是详细信息的获取。

问题也是有的

比如最迫切的应该是日志系统，不能老是出了错没地方找吧。

第二个就是排重的问题。目前为止并没有加入任何去重机制，所以数据库别看有几万条数据了，实际上排重下来也没多少。

针对这个问题，我想到的方法就是每次完成了一个用户的读取，就把这个用户id存本地文件里。就算挂了，重启服务重新从本地文件读取id，然后继续走。

然后是性能问题。

上了`php7`以后，实测在`php-cli`下，对用户详细信息的抓取大概到170条左右就挂了。

这个很明显不行啊！目标是一百万的数据量。怎么能才100+的数据就挂掉？

还需要一些用户界面，这个倒是其次的，后面再讲啦。

好了，暂时如此


